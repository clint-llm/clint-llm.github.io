To evaluate the clinical relevance or importance of a significant result, one must be certain to consider the size of the effect.

- Conducting a review of the literature and examining reported results,

- Conducting pilot studies to get an indication of effects that might be seen in larger studies,

- Making educated guesses based on what is clinically or practically meaningful and informed by experience

- Using conventional recommendations for effect size measures

One common measure of effect is the correlation coefficient, r. In general, small effects, or r=.10, indicate that the effect explains 1% of the total variance. Likewise, r=.30 is considered a medium effect, and r=.50 is considered large, explaining 25% of the variance and holding greater clinical relevance. The square of a correlational r-value indicates the proportion of variance explained by the relationship tested. Similarly, confidence intervals offer a way to determine the clinical strength or magnitude of observed effects.

It is also important to note that although a study may be designed and statistically tested in a way that suggests inference and causation could be concluded (e.g., longitudinal observations of change over time), only studies that employ a randomized and/or controlled design will permit causative declarations to be made from their results.